#!/usr/bin/env python3
import json
import sqlite3
import urllib.request
import urllib.parse
import re
import gzip
from http.server import HTTPServer, BaseHTTPRequestHandler
from urllib.parse import urlparse, parse_qs

# CORS headers
CORS_HEADERS = {
    'Access-Control-Allow-Origin': '*',
    'Access-Control-Allow-Methods': 'GET, POST, PUT, DELETE, OPTIONS',
    'Access-Control-Allow-Headers': 'Content-Type, Authorization'
}

class FacebookAdsExtractor:
    """–ö–ª–∞—Å –¥–ª—è –≤–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è –¥–∞–Ω–∏—Ö Facebook —Ä–µ–∫–ª–∞–º–Ω–∏—Ö –∫–∞–±—ñ–Ω–µ—Ç—ñ–≤ —á–µ—Ä–µ–∑ cookies"""
    
    def __init__(self, cookies, user_agent, facebook_id=None):
        self.cookies = cookies
        self.user_agent = user_agent or 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        self.facebook_id = facebook_id
        self.session_tokens = {}
        
    def get_base_headers(self, additional_headers=None):
        """–ë–∞–∑–æ–≤—ñ –∑–∞–≥–æ–ª–æ–≤–∫–∏ –¥–ª—è –∑–∞–ø–∏—Ç—ñ–≤"""
        headers = {
            'User-Agent': self.user_agent,
            'Cookie': self.cookies,
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.9,uk;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'none'
        }
        
        if additional_headers:
            headers.update(additional_headers)
            
        return headers
        
    def extract_ad_accounts_data(self):
        """–ì–æ–ª–æ–≤–Ω–∏–π –º–µ—Ç–æ–¥ –≤–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è –¥–∞–Ω–∏—Ö —Ä–µ–∫–ª–∞–º–Ω–∏—Ö –∫–∞–±—ñ–Ω–µ—Ç—ñ–≤"""
        print(f"üîç –ü–æ—á–∏–Ω–∞—î–º–æ –≤–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è –¥–∞–Ω–∏—Ö –¥–ª—è Facebook ID: {self.facebook_id}")
        
        # –ú–µ—Ç–æ–¥ 1: –í–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è –∑ HTML —Å—Ç–æ—Ä—ñ–Ω–∫–∏ Ads Manager
        html_data = self.try_html_extraction()
        if html_data:
            return html_data
            
        # –ú–µ—Ç–æ–¥ 2: –°–ø—Ä–æ–±–∞ —á–µ—Ä–µ–∑ –≤–Ω—É—Ç—Ä—ñ—à–Ω—ñ GraphQL endpoints
        graphql_data = self.try_internal_graphql()
        if graphql_data:
            return graphql_data
            
        # –ú–µ—Ç–æ–¥ 3: Fallback - –±–∞–∑–æ–≤–∞ —Å—Ç–æ—Ä—ñ–Ω–∫–∞ Facebook
        fallback_data = self.try_fallback_extraction()
        if fallback_data:
            return fallback_data
            
        raise Exception('–ù–µ –≤–¥–∞–ª–æ—Å—è –≤–∏—Ç—è–≥–Ω—É—Ç–∏ –¥–∞–Ω—ñ –∂–æ–¥–Ω–∏–º –º–µ—Ç–æ–¥–æ–º')
    
    def try_html_extraction(self):
        """–ú–µ—Ç–æ–¥ 1: –í–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è –∑ HTML —Å—Ç–æ—Ä—ñ–Ω–∫–∏ Ads Manager"""
        print('üîç –ü—Ä–æ–±—É—î–º–æ HTML extraction –∑ Ads Manager...')
        
        try:
            # –ó–∞–ø–∏—Ç—É—î–º–æ Ads Manager —Å—Ç–æ—Ä—ñ–Ω–∫—É
            ads_manager_url = "https://www.facebook.com/adsmanager/manage/campaigns"
            headers = self.get_base_headers()
            
            request = urllib.request.Request(ads_manager_url)
            for key, value in headers.items():
                request.add_header(key, value)
            
            print(f"üåê –ó–∞–ø–∏—Ç—É—î–º–æ: {ads_manager_url}")
            
            with urllib.request.urlopen(request, timeout=30) as response:
                # –û–±—Ä–æ–±–ª—è—î–º–æ –≤—ñ–¥–ø–æ–≤—ñ–¥—å
                raw_data = response.read()
                
                # –°–ø—Ä–æ–±–∞ –¥–µ–∫–æ–¥—É–≤–∞–Ω–Ω—è –∑ —Ä—ñ–∑–Ω–∏–º–∏ –º–µ—Ç–æ–¥–∞–º–∏
                try:
                    # –°–ø–æ—á–∞—Ç–∫—É –ø–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ —Ü–µ gzip
                    if response.info().get('Content-Encoding') == 'gzip':
                        html = gzip.decompress(raw_data).decode('utf-8')
                    else:
                        html = raw_data.decode('utf-8')
                except UnicodeDecodeError:
                    # –Ø–∫—â–æ utf-8 –Ω–µ –ø—Ä–∞—Ü—é—î, –ø—Ä–æ–±—É—î–º–æ latin-1
                    try:
                        html = raw_data.decode('latin-1')
                    except:
                        # –û—Å—Ç–∞–Ω–Ω—ñ–π resort - —ñ–≥–Ω–æ—Ä—É—î–º–æ –ø–æ–º–∏–ª–∫–∏
                        html = raw_data.decode('utf-8', errors='ignore')
            
            print(f"üìÑ –û—Ç—Ä–∏–º–∞–Ω–æ HTML: {len(html)} —Å–∏–º–≤–æ–ª—ñ–≤")
            
            # –í–∏—Ç—è–≥—É—î–º–æ —Ç–æ–∫–µ–Ω–∏ –∑ HTML
            fb_dtsg = self._extract_token(html, r'"DTSGInitData",\[\],\{"token":"([^"]+)"')
            lsd = self._extract_token(html, r'"LSD",\[\],\{"token":"([^"]+)"')
            
            if fb_dtsg and lsd:
                print(f"üìã –í–∏—Ç—è–≥–Ω—É—Ç–æ session —Ç–æ–∫–µ–Ω–∏: fb_dtsg, lsd")
                self.session_tokens = {'fb_dtsg': fb_dtsg, 'lsd': lsd}
            
            # –®—É–∫–∞—î–º–æ ad account –¥–∞–Ω—ñ –≤ HTML
            ad_account_patterns = [
                r'"adAccountID":"(\d+)"',
                r'"account_id":"(\d+)"',
                r'act_(\d+)',
                r'"AdAccount","(\d+)"',
                r'"id":"act_(\d+)"'
            ]
            
            found_accounts = set()
            for pattern in ad_account_patterns:
                matches = re.findall(pattern, html)
                found_accounts.update(matches)
            
            print(f"üìä –ó–Ω–∞–π–¥–µ–Ω–æ {len(found_accounts)} —É–Ω—ñ–∫–∞–ª—å–Ω–∏—Ö ID —Ä–µ–∫–ª–∞–º–Ω–∏—Ö –∫–∞–±—ñ–Ω–µ—Ç—ñ–≤")
            
            if found_accounts:
                accounts_data = []
                for account_id in list(found_accounts)[:20]:  # –û–±–º–µ–∂—É—î–º–æ –¥–æ 20
                    accounts_data.append({
                        'id': f'act_{account_id}',
                        'account_id': account_id,
                        'name': f'Account {account_id}',
                        'source': 'html_extraction',
                        'currency': 'USD',
                        'account_status': 'ACTIVE'
                    })
                
                print(f'‚úÖ HTML extraction —É—Å–ø—ñ—à–Ω–∏–π: {len(accounts_data)} –∫–∞–±—ñ–Ω–µ—Ç—ñ–≤')
                return {'data': accounts_data, 'method': 'html_extraction'}
            
        except Exception as e:
            print(f'‚ùå HTML extraction –ø—Ä–æ–≤–∞–ª–∏–≤—Å—è: {e}')
            
        return None
    
    def try_internal_graphql(self):
        """–ú–µ—Ç–æ–¥ 2: –í–Ω—É—Ç—Ä—ñ—à–Ω—ñ GraphQL endpoints"""
        print('üîç –ü—Ä–æ–±—É—î–º–æ Internal GraphQL...')
        
        if not self.session_tokens.get('fb_dtsg') or not self.session_tokens.get('lsd'):
            print('‚ö†Ô∏è –ù–µ–º–∞—î session —Ç–æ–∫–µ–Ω—ñ–≤ –¥–ª—è GraphQL')
            return None
            
        try:
            graphql_url = "https://www.facebook.com/api/graphql/"
            
            payload = {
                'fb_dtsg': self.session_tokens['fb_dtsg'],
                'lsd': self.session_tokens['lsd'],
                'variables': json.dumps({"limit": 50}),
                'doc_id': '2140584719566580',
                'server_timestamps': 'true'
            }
            
            headers = self.get_base_headers({
                'Content-Type': 'application/x-www-form-urlencoded',
                'X-FB-DTSG': self.session_tokens['fb_dtsg'],
                'X-FB-LSD': self.session_tokens['lsd'],
                'Origin': 'https://www.facebook.com',
                'Referer': 'https://www.facebook.com/adsmanager/'
            })
            
            data = urllib.parse.urlencode(payload).encode('utf-8')
            request = urllib.request.Request(graphql_url, data=data)
            
            for key, value in headers.items():
                request.add_header(key, value)
            
            with urllib.request.urlopen(request, timeout=30) as response:
                response_data = response.read().decode('utf-8')
            
            # –°–ø—Ä–æ–±–∞ –ø–∞—Ä—Å–∏–Ω–≥—É JSON
            try:
                json_data = json.loads(response_data)
                if json_data and 'data' in json_data:
                    print('‚úÖ Internal GraphQL —É—Å–ø—ñ—à–Ω–∏–π')
                    return {'data': json_data, 'method': 'internal_graphql'}
            except:
                pass
                
        except Exception as e:
            print(f'‚ùå Internal GraphQL –ø—Ä–æ–≤–∞–ª–∏–≤—Å—è: {e}')
            
        return None
    
    def try_fallback_extraction(self):
        """–ú–µ—Ç–æ–¥ 3: Fallback - –±–∞–∑–æ–≤–∞ —Å—Ç–æ—Ä—ñ–Ω–∫–∞ Facebook"""
        print('üîç –ü—Ä–æ–±—É—î–º–æ Fallback extraction...')
        
        try:
            # –ó–∞–ø–∏—Ç—É—î–º–æ –≥–æ–ª–æ–≤–Ω—É —Å—Ç–æ—Ä—ñ–Ω–∫—É Facebook
            facebook_url = "https://www.facebook.com/"
            headers = self.get_base_headers()
            
            request = urllib.request.Request(facebook_url)
            for key, value in headers.items():
                request.add_header(key, value)
            
            with urllib.request.urlopen(request, timeout=30) as response:
                raw_data = response.read()
                
                # –û–±—Ä–æ–±–ª—è—î–º–æ –≤—ñ–¥–ø–æ–≤—ñ–¥—å –∑ —É—Ä–∞—Ö—É–≤–∞–Ω–Ω—è–º —Ä—ñ–∑–Ω–∏—Ö –∫–æ–¥—É–≤–∞–Ω—å
                try:
                    if response.info().get('Content-Encoding') == 'gzip':
                        html = gzip.decompress(raw_data).decode('utf-8')
                    else:
                        html = raw_data.decode('utf-8')
                except UnicodeDecodeError:
                    try:
                        html = raw_data.decode('latin-1')
                    except:
                        html = raw_data.decode('utf-8', errors='ignore')
            
            # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ —É–≤—ñ–π—à–ª–∏
            if 'login' in html.lower() or 'log in' in html.lower():
                print('‚ùå Cookies –Ω–µ –≤–∞–ª—ñ–¥–Ω—ñ - –ø–µ—Ä–µ–Ω–∞–ø—Ä–∞–≤–ª—è—î –Ω–∞ login')
                return None
            
            print('‚úÖ Cookies –ø—Ä–∞—Ü—é—é—Ç—å - —É–≤—ñ–π—à–ª–∏ –≤ Facebook')
            
            # –ü–æ–≤–µ—Ä—Ç–∞—î–º–æ –±–∞–∑–æ–≤—É —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é
            return {
                'data': [{
                    'id': f'act_{self.facebook_id}',
                    'account_id': self.facebook_id,
                    'name': f'Account {self.facebook_id}',
                    'source': 'fallback_extraction',
                    'status': 'authenticated'
                }],
                'method': 'fallback_extraction'
            }
            
        except Exception as e:
            print(f'‚ùå Fallback extraction –ø—Ä–æ–≤–∞–ª–∏–≤—Å—è: {e}')
            
        return None
    
    def _extract_token(self, html, pattern):
        """–î–æ–ø–æ–º—ñ–∂–Ω–∏–π –º–µ—Ç–æ–¥ –¥–ª—è –≤–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è —Ç–æ–∫–µ–Ω—ñ–≤"""
        match = re.search(pattern, html)
        return match.group(1) if match else None


class FacebookScraperHandler(BaseHTTPRequestHandler):
    """HTTP Request Handler –¥–ª—è Facebook scraper backend"""
    
    def do_OPTIONS(self):
        self.send_response(200)
        for key, value in CORS_HEADERS.items():
            self.send_header(key, value)
        self.end_headers()
    
    def do_GET(self):
        """Handle GET requests"""
        parsed_path = urlparse(self.path)
        path_parts = parsed_path.path.strip('/').split('/')
        
        if parsed_path.path == '/' or parsed_path.path == '':
            self.handle_root()
        elif path_parts == ['api', 'facebook', 'accounts']:
            self.handle_get_facebook_accounts()
        elif (len(path_parts) == 5 and path_parts[:3] == ['api', 'facebook', 'accounts'] 
              and path_parts[4] == 'adaccounts'):
            account_id = path_parts[3]
            self.handle_get_ad_accounts(account_id)
        else:
            self.send_404()
    
    def handle_root(self):
        """–ì–æ–ª–æ–≤–Ω–∞ —Å—Ç–æ—Ä—ñ–Ω–∫–∞ –∑ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—î—é –ø—Ä–æ API"""
        self.send_response(200)
        for key, value in CORS_HEADERS.items():
            self.send_header(key, value)
        self.send_header('Content-Type', 'application/json')
        self.end_headers()
        
        response = {
            'service': 'Facebook Scraper Backend',
            'version': '3.0',
            'description': 'Backend –¥–ª—è –≤–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è Facebook —Ä–µ–∫–ª–∞–º–Ω–∏—Ö –∫–∞–±—ñ–Ω–µ—Ç—ñ–≤ —á–µ—Ä–µ–∑ cookies',
            'methods': ['HTML Extraction', 'Internal GraphQL', 'Fallback Extraction'],
            'endpoints': {
                'GET /': '–Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ API',
                'GET /api/facebook/accounts': '–°–ø–∏—Å–æ–∫ Facebook –∞–∫–∞—É–Ω—Ç—ñ–≤',
                'GET /api/facebook/accounts/{id}/adaccounts': '–†–µ–∫–ª–∞–º–Ω—ñ –∫–∞–±—ñ–Ω–µ—Ç–∏ –¥–ª—è –∞–∫–∞—É–Ω—Ç–∞'
            },
            'status': 'ready'
        }
        self.wfile.write(json.dumps(response, ensure_ascii=False, indent=2).encode('utf-8'))
    
    def handle_get_facebook_accounts(self):
        """–û—Ç—Ä–∏–º–∞–Ω–Ω—è —Å–ø–∏—Å–∫—É Facebook –∞–∫–∞—É–Ω—Ç—ñ–≤ –∑ –±–∞–∑–∏"""
        try:
            conn = sqlite3.connect('ai_buyer.db')
            cursor = conn.cursor()
            
            cursor.execute("""
                SELECT id, facebook_id, name, access_token, cookies_data, user_agent, created_at 
                FROM facebook_accounts 
                ORDER BY created_at DESC
            """)
            
            accounts = []
            for row in cursor.fetchall():
                accounts.append({
                    'id': row[0],
                    'facebook_id': row[1],
                    'name': row[2],
                    'access_token': row[3][:20] + '...' if row[3] else None,
                    'has_cookies': bool(row[4]),
                    'has_user_agent': bool(row[5]),
                    'cookies_length': len(row[4]) if row[4] else 0,
                    'created_at': row[6]
                })
            
            conn.close()
            
            self.send_response(200)
            for key, value in CORS_HEADERS.items():
                self.send_header(key, value)
            self.send_header('Content-Type', 'application/json')
            self.end_headers()
            
            response = {
                'status': 'success',
                'data': accounts,
                'count': len(accounts)
            }
            
            self.wfile.write(json.dumps(response, ensure_ascii=False).encode('utf-8'))
            
        except Exception as e:
            print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –æ—Ç—Ä–∏–º–∞–Ω–Ω—è –∞–∫–∞—É–Ω—Ç—ñ–≤: {e}")
            self.send_error_response(500, f"Database error: {str(e)}")
    
    def handle_get_ad_accounts(self, account_id):
        """–û—Ç—Ä–∏–º–∞–Ω–Ω—è —Ä–µ–∫–ª–∞–º–Ω–∏—Ö –∫–∞–±—ñ–Ω–µ—Ç—ñ–≤ —á–µ—Ä–µ–∑ scraping"""
        try:
            # –û—Ç—Ä–∏–º—É—î–º–æ –¥–∞–Ω—ñ –∞–∫–∞—É–Ω—Ç–∞ –∑ –±–∞–∑–∏
            conn = sqlite3.connect('ai_buyer.db')
            cursor = conn.cursor()
            
            cursor.execute("""
                SELECT facebook_id, name, access_token, cookies_data, user_agent 
                FROM facebook_accounts 
                WHERE id = ?
            """, (account_id,))
            
            account_data = cursor.fetchone()
            conn.close()
            
            if not account_data:
                self.send_error_response(404, 'Facebook –∞–∫–∞—É–Ω—Ç –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∏–π')
                return
            
            facebook_id, name, access_token, cookies_data, user_agent = account_data
            
            print(f"üîç –û–±—Ä–æ–±–ª—è—î–º–æ –∞–∫–∞—É–Ω—Ç {account_id}")
            print(f"   FB ID: {facebook_id}")
            print(f"   Name: {name}")
            print(f"   Cookies: {'–Ñ' if cookies_data else '–í—ñ–¥—Å—É—Ç–Ω—ñ'} ({len(cookies_data) if cookies_data else 0} —Å–∏–º–≤–æ–ª—ñ–≤)")
            print(f"   User Agent: {'–Ñ' if user_agent else '–í—ñ–¥—Å—É—Ç–Ω—ñ–π'}")
            
            if not cookies_data:
                self.send_error_response(400, 'Cookies –æ–±–æ–≤\'—è–∑–∫–æ–≤—ñ –¥–ª—è scraping –ø—ñ–¥—Ö–æ–¥—É')
                return
            
            # –°—Ç–≤–æ—Ä—é—î–º–æ –µ–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä —ñ –≤–∏—Ç—è–≥—É—î–º–æ –¥–∞–Ω—ñ
            extractor = FacebookAdsExtractor(
                cookies=cookies_data,
                user_agent=user_agent,
                facebook_id=facebook_id
            )
            
            # –í–∏—Ç—è–≥—É—î–º–æ –¥–∞–Ω—ñ –ø—Ä–æ —Ä–µ–∫–ª–∞–º–Ω—ñ –∫–∞–±—ñ–Ω–µ—Ç–∏
            ads_data = extractor.extract_ad_accounts_data()
            
            if ads_data:
                method = ads_data.get('method', 'unknown')
                data_count = len(ads_data.get('data', []))
                print(f"‚úÖ –£—Å–ø—ñ—à–Ω–æ –≤–∏—Ç—è–≥–Ω—É—Ç–æ {data_count} –∫–∞–±—ñ–Ω–µ—Ç—ñ–≤ –º–µ—Ç–æ–¥–æ–º: {method}")
                
                self.send_response(200)
                for key, value in CORS_HEADERS.items():
                    self.send_header(key, value)
                self.send_header('Content-Type', 'application/json')
                self.end_headers()
                
                response = {
                    'status': 'success',
                    'account_id': account_id,
                    'facebook_id': facebook_id,
                    'method': method,
                    'count': data_count,
                    'data': ads_data
                }
                self.wfile.write(json.dumps(response, ensure_ascii=False).encode('utf-8'))
            else:
                self.send_error_response(400, '–ù–µ –≤–¥–∞–ª–æ—Å—è –æ—Ç—Ä–∏–º–∞—Ç–∏ –¥–∞–Ω—ñ –ø—Ä–æ —Ä–µ–∫–ª–∞–º–Ω—ñ –∫–∞–±—ñ–Ω–µ—Ç–∏')
                
        except Exception as e:
            print(f"üö´ –ü–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏ ad accounts: {e}")
            self.send_error_response(500, f'Scraping error: {str(e)}')
    
    def send_404(self):
        """–í—ñ–¥–ø—Ä–∞–≤–∫–∞ 404 –ø–æ–º–∏–ª–∫–∏"""
        self.send_response(404)
        for key, value in CORS_HEADERS.items():
            self.send_header(key, value)
        self.send_header('Content-Type', 'application/json')
        self.end_headers()
        
        response = {'status': 'error', 'detail': 'Endpoint not found'}
        self.wfile.write(json.dumps(response).encode())
    
    def send_error_response(self, status_code, message):
        """–í—ñ–¥–ø—Ä–∞–≤–∫–∞ –ø–æ–º–∏–ª–∫–∏"""
        self.send_response(status_code)
        for key, value in CORS_HEADERS.items():
            self.send_header(key, value)
        self.send_header('Content-Type', 'application/json')
        self.end_headers()
        
        response = {'status': 'error', 'detail': message}
        self.wfile.write(json.dumps(response, ensure_ascii=False).encode('utf-8'))


def main():
    server_address = ('localhost', 8000)
    httpd = HTTPServer(server_address, FacebookScraperHandler)
    
    print("üöÄ Facebook Scraper Backend v3.0 –∑–∞–ø—É—â–µ–Ω–∏–π –Ω–∞ http://localhost:8000")
    print("üìã –ú–µ—Ç–æ–¥–∏ –≤–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è:")
    print("   1Ô∏è‚É£ HTML Extraction - –ø–∞—Ä—Å–∏–Ω–≥ Ads Manager —Å—Ç–æ—Ä—ñ–Ω–∫–∏")
    print("   2Ô∏è‚É£ Internal GraphQL - –≤–Ω—É—Ç—Ä—ñ—à–Ω—ñ Facebook API")
    print("   3Ô∏è‚É£ Fallback Extraction - –±–∞–∑–æ–≤–∞ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∞ cookies")
    print("üìã API endpoints:")
    print("   GET /                                      - –Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ API")
    print("   GET /api/facebook/accounts                 - –°–ø–∏—Å–æ–∫ –∞–∫–∞—É–Ω—Ç—ñ–≤")
    print("   GET /api/facebook/accounts/{id}/adaccounts - –†–µ–∫–ª–∞–º–Ω—ñ –∫–∞–±—ñ–Ω–µ—Ç–∏")
    
    try:
        httpd.serve_forever()
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è  –°–µ—Ä–≤–µ—Ä –∑—É–ø–∏–Ω–µ–Ω–∏–π")
        httpd.shutdown()


if __name__ == '__main__':
    main()